{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9739372,"sourceType":"datasetVersion","datasetId":5961287},{"sourceId":9741204,"sourceType":"datasetVersion","datasetId":5962620},{"sourceId":9750080,"sourceType":"datasetVersion","datasetId":5969264}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import StepLR\n\nimport numpy as np\nimport random\n\nfrom copy import deepcopy","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:46.445291Z","iopub.execute_input":"2024-10-29T07:37:46.445682Z","iopub.status.idle":"2024-10-29T07:37:51.103178Z","shell.execute_reply.started":"2024-10-29T07:37:46.445638Z","shell.execute_reply":"2024-10-29T07:37:51.101925Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(12)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:51.105574Z","iopub.execute_input":"2024-10-29T07:37:51.106268Z","iopub.status.idle":"2024-10-29T07:37:51.122181Z","shell.execute_reply.started":"2024-10-29T07:37:51.106212Z","shell.execute_reply":"2024-10-29T07:37:51.120915Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class skeleton_LSTM(nn.Module):\n    def __init__(self, feature_dim, output_dim):\n        super(skeleton_LSTM, self).__init__()\n        \n        self.feature_dim = feature_dim\n        self.output_dim = output_dim\n        \n        self.lstm1 = nn.LSTM(input_size=self.feature_dim, hidden_size=128, num_layers=1, batch_first=True)\n        self.layer_norm1 = nn.LayerNorm(128)\n        \n        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=1, batch_first=True)\n        self.layer_norm2 = nn.LayerNorm(256)\n        \n        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1, batch_first=True)\n        self.layer_norm3 = nn.LayerNorm(512)\n        \n        self.fc1 = nn.Linear(512,256)\n        self.fc2 = nn.Linear(256,output_dim)\n        \n    def forward(self, x):\n        x, _ = self.lstm1(x)\n        x = self.layer_norm1(x)\n        \n        x, _ = self.lstm2(x)\n        x = self.layer_norm2(x)\n        \n        x, (hn, cn) = self.lstm3(x)\n        x = self.layer_norm3(x)\n        \n        x = F.relu(self.fc1(x[:,-1,:]))\n        embedding = self.fc2(x)\n        \n        return embedding\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:51.123664Z","iopub.execute_input":"2024-10-29T07:37:51.124163Z","iopub.status.idle":"2024-10-29T07:37:51.139389Z","shell.execute_reply.started":"2024-10-29T07:37:51.124110Z","shell.execute_reply":"2024-10-29T07:37:51.138249Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class head(nn.Module) :\n    def __init__(self):\n        super(head, self).__init__()\n        \n        # Feedforward layers\n        self.fc1 = nn.Linear(64, 32)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(32, 1)  # Output layer has 1 unit for binary classification\n        self.sigmoid = nn.Sigmoid()  # Sigmoid for probability output\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return x\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:51.142468Z","iopub.execute_input":"2024-10-29T07:37:51.142968Z","iopub.status.idle":"2024-10-29T07:37:51.152063Z","shell.execute_reply.started":"2024-10-29T07:37:51.142908Z","shell.execute_reply":"2024-10-29T07:37:51.150736Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset\n\nangle = [['left_biceps', 'left_forearm'],\n         ['right_biceps', 'right_forearm'],\n         ['between_shoulders', 'left_body'],\n         ['between_shoulders', 'right_body'],\n         ['between_shoulders', 'rigth_neck'],\n         ['between_shoulders', 'left_neck'],\n         ['between_pelvis','left_thigh'],\n         ['between_pelvis','right_thigh'],\n         ['right_thigh','right_calf'],\n         ['left_thigh','left_calf'],\n         ['right_body','right_thigh'],\n         ['left_body','left_thigh']\n        ]\n         \n\nbody_parts = {'left_biceps': [11, 13],\n              'left_forearm': [13, 15],\n              'right_biceps': [12, 14],\n              'right_forearm': [14, 16],\n              'between_shoulders': [11, 12],\n              'left_body': [11, 23],\n              'right_body': [12, 24],\n              'between_pelvis': [23, 24],\n              'left_thigh': [23, 25],\n              'left_calf': [25, 27],\n              'right_thigh': [24, 26],\n              'right_calf': [26, 28],\n              'left_neck': [9, 11],\n              'rigth_neck': [10, 12]}\n\n\ndef calculate_angles(matrix1, matrix2):\n    dot_product = np.einsum('ij,ij->i', matrix1, matrix2)\n    norm1 = np.linalg.norm(matrix1, axis=1)\n    norm2 = np.linalg.norm(matrix2, axis=1)\n    cos_theta = dot_product / (norm1 * norm2)\n    angles = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n    return angles\n\n\ndef make_df_angle(path):\n    df = pd.read_csv(path)\n    df_angle = pd.DataFrame()\n\n    for body_parts1, body_parts2 in angle:\n        body_parts1_vec = body_parts[body_parts1]\n        body_parts2_vec = body_parts[body_parts2]\n\n        # 벡터 계산\n        vec_mat1 = df.iloc[:, body_parts1_vec[0]*3+1:body_parts1_vec[0]*3+4].values - df.iloc[:, body_parts1_vec[1]*3+1:body_parts1_vec[1]*3+4].values\n        vec_mat2 = df.iloc[:, body_parts2_vec[0]*3+1:body_parts2_vec[0]*3+4].values - df.iloc[:, body_parts2_vec[1]*3+1:body_parts2_vec[1]*3+4].values\n\n        angles = calculate_angles(vec_mat1, vec_mat2)\n        df_angle[f'{body_parts1}_{body_parts2}'] = angles\n        \n    df_angle = df_angle.replace([np.inf, -np.inf], 0.0)\n    df_angle = df_angle.fillna(0.0)\n\n\n    return df_angle\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:51.153722Z","iopub.execute_input":"2024-10-29T07:37:51.154234Z","iopub.status.idle":"2024-10-29T07:37:51.176370Z","shell.execute_reply.started":"2024-10-29T07:37:51.154180Z","shell.execute_reply":"2024-10-29T07:37:51.174911Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class LandmarkDataset(Dataset):\n    def __init__(self,path):\n        self.root_dir = path\n        self.data = []\n        self.labels = []\n        self.label_to_indices = {}\n        self.min_sequence_length = float('inf')\n\n        # 디렉토리 탐색 및 최소 시퀀스 길이 계산\n        for dance_name in os.listdir(self.root_dir):\n            dance_path = os.path.join(self.root_dir, dance_name)\n            if os.path.isdir(dance_path):\n                for csv_file in os.listdir(dance_path):\n                    # '_F'로 끝나는 파일은 제외\n                    if csv_file.endswith(\".csv\") and not csv_file.endswith(\"_F.csv\"):\n                        file_path = os.path.join(dance_path, csv_file)\n                        self.data.append(file_path)\n                        self.labels.append(dance_name)\n\n                        if dance_name not in self.label_to_indices:\n                            self.label_to_indices[dance_name] = []\n                        self.label_to_indices[dance_name].append(len(self.data) - 1)\n\n                        # 각 CSV 파일의 시퀀스 길이를 체크하여 최소 시퀀스 길이 업데이트\n                        df_angle = make_df_angle(file_path)\n                        sequence_length = len(df_angle)\n                        if sequence_length < self.min_sequence_length:\n                            self.min_sequence_length = sequence_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # 현재 샘플의 라벨 및 파일 경로\n        label = self.labels[idx]\n        file_path1 = self.data[idx]\n\n        # 같은 클래스의 다른 파일을 선택하여 positive 쌍 구성\n        positive_idx = np.random.choice(self.label_to_indices[label])\n        while positive_idx == idx:\n            positive_idx = np.random.choice(self.label_to_indices[label])\n        file_path2 = self.data[positive_idx]\n\n        # 랜덤으로 다른 클래스의 샘플을 선택하여 negative 쌍 구성\n        neg_label = np.random.choice([l for l in self.label_to_indices if l != label])\n        negative_idx = np.random.choice(self.label_to_indices[neg_label])\n        file_path3 = self.data[negative_idx]\n\n        # 각 파일에서 관절 간 각도를 계산\n        angles1 = make_df_angle(file_path1).values[:self.min_sequence_length]\n        angles2 = make_df_angle(file_path2).values[:self.min_sequence_length]\n        angles3 = make_df_angle(file_path3).values[:self.min_sequence_length]\n\n        # numpy array를 torch tensor로 변환\n        angles1 = torch.tensor(angles1, dtype=torch.float32)\n        angles2 = torch.tensor(angles2, dtype=torch.float32)\n        angles3 = torch.tensor(angles3, dtype=torch.float32)\n\n        # Positive 쌍은 (angles1, angles2), negative 쌍은 (angles1, angles3)\n        return angles1, angles2, angles3\n\n    def load_landmark(self, file_path):\n        df = pd.read_csv(file_path)\n        df = df.drop(columns=['filename'])\n        landmarks = df.values[:self.min_sequence_length]\n        return landmarks","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:51.178412Z","iopub.execute_input":"2024-10-29T07:37:51.178877Z","iopub.status.idle":"2024-10-29T07:37:51.201855Z","shell.execute_reply.started":"2024-10-29T07:37:51.178827Z","shell.execute_reply":"2024-10-29T07:37:51.200471Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class TripletContrastiveLoss(nn.Module):\n    def __init__(self, temperature=0.1):\n        super(TripletContrastiveLoss, self).__init__()\n        self.temperature = temperature\n\n    def forward(self, anchor, positive, negative):\n        # Normalize features\n        anchor, positive, negative = F.normalize(anchor, dim=1), F.normalize(positive, dim=1), F.normalize(negative, dim=1)\n        \n        # Calculate similarities\n        pos_sim = torch.exp(torch.sum(anchor * positive, dim=1) / self.temperature)  # Anchor-Positive similarity\n        neg_sim = torch.exp(torch.sum(anchor * negative, dim=1) / self.temperature)  # Anchor-Negative similarity\n\n        # Loss calculation: maximize anchor-positive similarity, minimize anchor-negative similarity\n        loss = -torch.log(pos_sim / (pos_sim + neg_sim)).mean()\n        return loss\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:51.203493Z","iopub.execute_input":"2024-10-29T07:37:51.203877Z","iopub.status.idle":"2024-10-29T07:37:51.218568Z","shell.execute_reply.started":"2024-10-29T07:37:51.203837Z","shell.execute_reply":"2024-10-29T07:37:51.217426Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 데이터셋과 데이터로더\nbatch_size = 8\ntrain_dataset = LandmarkDataset('/kaggle/input/nipa-sample/sample_video')\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\nval_dataset = LandmarkDataset('/kaggle/input/nipa-val')\nval_dataloader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:51.220389Z","iopub.execute_input":"2024-10-29T07:37:51.220880Z","iopub.status.idle":"2024-10-29T07:37:53.676775Z","shell.execute_reply.started":"2024-10-29T07:37:51.220822Z","shell.execute_reply":"2024-10-29T07:37:53.675448Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# 하이퍼파라미터\nfeature_dim = len(angle)\noutput_dim = 64\nnum_epochs = 50\nlearning_rate = 0.001\ntemperature = .05\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:53.678686Z","iopub.execute_input":"2024-10-29T07:37:53.679785Z","iopub.status.idle":"2024-10-29T07:37:53.687546Z","shell.execute_reply.started":"2024-10-29T07:37:53.679726Z","shell.execute_reply":"2024-10-29T07:37:53.686097Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# 모델, 손실 함수, 옵티마이저 초기화\nmodel = skeleton_LSTM(feature_dim, output_dim).to(device)\nclassification = head().to(device)\n\ncriterion1 = TripletContrastiveLoss(temperature=temperature)\ncriterion2 = nn.BCELoss()\ncriterion3 = nn.BCELoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = StepLR(optimizer, step_size=10, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:53.691487Z","iopub.execute_input":"2024-10-29T07:37:53.691961Z","iopub.status.idle":"2024-10-29T07:37:54.938224Z","shell.execute_reply.started":"2024-10-29T07:37:53.691916Z","shell.execute_reply":"2024-10-29T07:37:54.937040Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# 학습 루프\n\nbest_val_loss = np.inf\npatience = 10\nepochs_no_improve = 0\n\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    model.train()\n    classification.train()\n    \n    for batch_idx, (anchor, pos, neg) in enumerate(train_dataloader):\n            \n        optimizer.zero_grad()\n\n        # Positive 쌍과 Negative 쌍을 모델에 각각 통과\n        \n        anchor = anchor.to(device)\n        pos = pos.to(device)\n        neg = neg.to(device)\n        \n        anchor_emb = model(anchor)\n        pos_emb = model(pos)\n        neg_emb = model(neg)\n\n        # Contrastive Loss 계산\n        loss1 = criterion1(anchor_emb, pos_emb, neg_emb)\n        \n        pos_classification = classification(torch.add(anchor_emb,pos_emb))\n        loss2 = criterion2(pos_classification,torch.full((pos_classification.shape[0],1),1.).to(device))\n        \n        neg_classification = classification(torch.add(anchor_emb,neg_emb))\n        loss3 = criterion2(neg_classification,torch.full((pos_classification.shape[0],1),0.).to(device))\n        \n        loss = loss1+loss2+loss3\n        train_loss += loss1.item()\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for batch_idx, (anchor, pos, neg) in enumerate(val_dataloader):\n            anchor, pos, neg = anchor.to(device), pos.to(device), neg.to(device)\n\n            anchor_emb = model(anchor)\n            pos_emb = model(pos)\n            neg_emb = model(neg)\n            \n            loss = criterion1(anchor_emb, pos_emb, neg_emb)\n            val_loss += loss.item()\n            \n            \n    # Early Stopping 체크\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        epochs_no_improve = 0  # Improvement이 있으면 카운트 리셋\n        best_model = deepcopy(model)\n    else:\n        epochs_no_improve += 1\n\n    if epochs_no_improve >= patience:\n        print(\"Early stopping triggered!\")\n        break\n\n\n\n#         if batch_idx % 10 == 0:\n#             print(\n#                 f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(dataloader)}], Loss: {loss.item():.4f}')\n\n    # 에폭마다 평균 손실을 기록\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Average Loss: {train_loss / len(train_dataloader):.4f}, Validation Average Loss: {val_loss:.4f}')\n\nprint(\"Training complete!\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:37:54.939837Z","iopub.execute_input":"2024-10-29T07:37:54.940528Z","iopub.status.idle":"2024-10-29T07:40:14.125763Z","shell.execute_reply.started":"2024-10-29T07:37:54.940473Z","shell.execute_reply":"2024-10-29T07:40:14.123741Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch [1/50], Train Average Loss: 0.3646, Validation Average Loss: 0.3160\nEpoch [2/50], Train Average Loss: 0.1248, Validation Average Loss: 0.2395\nEpoch [3/50], Train Average Loss: 0.1474, Validation Average Loss: 0.4227\nEpoch [4/50], Train Average Loss: 0.0874, Validation Average Loss: 0.4106\nEpoch [5/50], Train Average Loss: 0.0992, Validation Average Loss: 0.2325\nEpoch [6/50], Train Average Loss: 0.0399, Validation Average Loss: 0.4275\nEpoch [7/50], Train Average Loss: 0.0748, Validation Average Loss: 0.3469\nEpoch [8/50], Train Average Loss: 0.0880, Validation Average Loss: 0.1923\nEpoch [9/50], Train Average Loss: 0.0085, Validation Average Loss: 0.3126\nEpoch [10/50], Train Average Loss: 0.0513, Validation Average Loss: 0.4540\nEpoch [11/50], Train Average Loss: 0.0499, Validation Average Loss: 0.2576\nEpoch [12/50], Train Average Loss: 0.0482, Validation Average Loss: 0.2070\nEpoch [13/50], Train Average Loss: 0.0837, Validation Average Loss: 0.5152\nEpoch [14/50], Train Average Loss: 0.0295, Validation Average Loss: 0.4908\nEpoch [15/50], Train Average Loss: 0.1281, Validation Average Loss: 0.2771\nEpoch [16/50], Train Average Loss: 0.0582, Validation Average Loss: 0.2866\nEpoch [17/50], Train Average Loss: 0.0519, Validation Average Loss: 0.3179\nEarly stopping triggered!\nTraining complete!\n","output_type":"stream"}]},{"cell_type":"code","source":"# 유클리디언 거리 계산\nbest_model.eval()\n\nseq_len = 15\n\norigin_path = '/kaggle/input/gmb-nipa/landmarks/landmarks/기본항목 집합곡 5/landmarks_3d_L.csv'\npos_path = '/kaggle/input/gmb-nipa/landmarks/landmarks/기본항목 집합곡 5/landmarks_3d_P.csv'\nneg_path = '/kaggle/input/gmb-nipa/landmarks/landmarks/Only One (보아)/landmarks_3d_P.csv'\n\norigin = make_df_angle(origin_path)\npos = make_df_angle(pos_path)\nneg = make_df_angle(neg_path)\n\norigin_input = torch.tensor(origin.iloc[seq_len:seq_len*2+1,].values).unsqueeze(0).to(torch.float32).to(device)\npos_input = torch.tensor(pos.iloc[seq_len:seq_len*2+1,].values).unsqueeze(0).to(torch.float32).to(device)\nneg_input = torch.tensor(neg.iloc[:seq_len,].values).unsqueeze(0).to(torch.float32).to(device)\n\norigin_emb = best_model(origin_input)\npos_emb = best_model(pos_input)\nneg_emb = best_model(neg_input)\n\npos_dist = torch.pow(F.pairwise_distance(origin_emb, pos_emb), 2)\nneg_dist = torch.pow(F.pairwise_distance(origin_emb, neg_emb), 2)\nprint(pos_dist)\nprint(neg_dist)\nneg_dist/pos_dist","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:47:11.777690Z","iopub.execute_input":"2024-10-29T07:47:11.778769Z","iopub.status.idle":"2024-10-29T07:47:11.896583Z","shell.execute_reply.started":"2024-10-29T07:47:11.778711Z","shell.execute_reply":"2024-10-29T07:47:11.895404Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"tensor([0.2325], grad_fn=<PowBackward0>)\ntensor([0.4968], grad_fn=<PowBackward0>)\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"tensor([2.1369], grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"# 정규화 후, 유클리디언 거리 계산\nbest_model.eval()\n\norigin = make_df_angle(origin_path)\npos = make_df_angle(pos_path)\nneg = make_df_angle(neg_path)\n\nnormed_origin_emb = F.normalize(origin_emb, dim=1)\nnormed_pos_emb = F.normalize(pos_emb, dim=1)\nnormed_neg_emb = F.normalize(neg_emb, dim=1)\n\npos_dist = torch.pow(F.pairwise_distance(normed_origin_emb, normed_pos_emb), 2)\nneg_dist = torch.pow(F.pairwise_distance(normed_origin_emb, normed_neg_emb), 2)\nprint(pos_dist)\nprint(neg_dist)\nneg_dist/pos_dist","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:47:12.018159Z","iopub.execute_input":"2024-10-29T07:47:12.018581Z","iopub.status.idle":"2024-10-29T07:47:12.109784Z","shell.execute_reply.started":"2024-10-29T07:47:12.018543Z","shell.execute_reply":"2024-10-29T07:47:12.108650Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"tensor([0.0043], grad_fn=<PowBackward0>)\ntensor([0.0093], grad_fn=<PowBackward0>)\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"tensor([2.1645], grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"def calc_dist(pos_path1, pos_path2, seq_len) :\n    best_model.eval()\n\n    pos1 = make_df_angle(pos_path1)\n    pos2 = make_df_angle(pos_path2)\n\n    pos1_input = torch.tensor(pos1.iloc[seq_len:seq_len*2+1,].values).unsqueeze(0).to(torch.float32).to(device)\n    pos2_input = torch.tensor(pos2.iloc[seq_len:seq_len*2+1,].values).unsqueeze(0).to(torch.float32).to(device)\n\n    pos1_emb = F.normalize(best_model(pos1_input), dim=1)\n    pos2_emb = F.normalize(best_model(pos2_input), dim=1)\n\n    pos_dist = torch.pow(F.pairwise_distance(pos1_emb, pos2_emb), 2)\n    return pos_dist","metadata":{"execution":{"iopub.status.busy":"2024-10-29T08:06:24.504111Z","iopub.execute_input":"2024-10-29T08:06:24.504559Z","iopub.status.idle":"2024-10-29T08:06:24.513502Z","shell.execute_reply.started":"2024-10-29T08:06:24.504517Z","shell.execute_reply":"2024-10-29T08:06:24.512299Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/nipa-sample/sample_video'\nl = []\nfor dance_name in os.listdir(path) :\n    seq_len = 20\n    \n    video_folder = os.path.join(path,dance_name)\n    pos1 = os.path.join(video_folder,os.listdir(video_folder)[1])\n    pos2 = os.path.join(video_folder,os.listdir(video_folder)[2])\n#     pos3 = os.path.join(video_folder,os.listdir(video_folder)[3])\n    \n    dist1 = calc_dist(pos1,pos2,seq_len)\n#     dist2 = calc_dist(pos3,pos2,seq_len)\n#     dist3 = calc_dist(pos1,pos3,seq_len)\n    l.append(dist1.item())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T08:24:40.584916Z","iopub.execute_input":"2024-10-29T08:24:40.586199Z","iopub.status.idle":"2024-10-29T08:24:41.320945Z","shell.execute_reply.started":"2024-10-29T08:24:40.586146Z","shell.execute_reply":"2024-10-29T08:24:41.319633Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"cnt = 0\nfor i in l :\n    if i <= 0.1 :\n        cnt += 1\n        \ncnt/len(l)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T08:24:41.913196Z","iopub.execute_input":"2024-10-29T08:24:41.913641Z","iopub.status.idle":"2024-10-29T08:24:41.921913Z","shell.execute_reply.started":"2024-10-29T08:24:41.913600Z","shell.execute_reply":"2024-10-29T08:24:41.920801Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"0.8"},"metadata":{}}]},{"cell_type":"code","source":"l","metadata":{"execution":{"iopub.status.busy":"2024-10-29T08:24:44.984314Z","iopub.execute_input":"2024-10-29T08:24:44.984805Z","iopub.status.idle":"2024-10-29T08:24:44.992320Z","shell.execute_reply.started":"2024-10-29T08:24:44.984748Z","shell.execute_reply":"2024-10-29T08:24:44.991267Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"[0.0035086588468402624,\n 0.002870474476367235,\n 0.05862519517540932,\n 0.0737084299325943,\n 0.1053171306848526,\n 0.06834540516138077,\n 0.024539299309253693,\n 0.14404559135437012,\n 0.004484932869672775,\n 0.014911270700395107]"},"metadata":{}}]},{"cell_type":"code","source":"# 정규화 후, 유클리디언 거리 계산\nbest_model.eval()\n\norigin = make_df_angle(origin_path)\npos = make_df_angle(pos_path)\nneg = make_df_angle(neg_path)\n\norigin_input = torch.tensor(origin.iloc[seq_len:seq_len*2+1,].values).unsqueeze(0).to(torch.float32).to(device)\npos_input = torch.tensor(pos.iloc[seq_len:seq_len*2+1,].values).unsqueeze(0).to(torch.float32).to(device)\nneg_input = torch.tensor(neg.iloc[:seq_len,].values).unsqueeze(0).to(torch.float32).to(device)\n\norigin_emb = F.normalize(best_model(origin_input), dim=1)\npos_emb = F.normalize(best_model(pos_input), dim=1)\nneg_emb = F.normalize(best_model(neg_input), dim=1)\n\npos_dist = torch.pow(F.pairwise_distance(origin_emb, pos_emb), 2)\nneg_dist = torch.pow(F.pairwise_distance(origin_emb, neg_emb), 2)\nprint(pos_dist)\nprint(neg_dist)\nneg_dist/pos_dist","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:46:41.219321Z","iopub.execute_input":"2024-10-29T07:46:41.219765Z","iopub.status.idle":"2024-10-29T07:46:41.329034Z","shell.execute_reply.started":"2024-10-29T07:46:41.219724Z","shell.execute_reply":"2024-10-29T07:46:41.327890Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"tensor([0.0043], grad_fn=<PowBackward0>)\ntensor([0.0093], grad_fn=<PowBackward0>)\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"tensor([2.1645], grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"from time import time\n\nmodel.eval()\n\nstart = time()\norigin_path = '/kaggle/input/nipa-sample/sample_video/100 (슈퍼엠)/landmarks_3d_L.csv'\norigin = make_df_angle(origin_path)\norigin_input = torch.tensor(origin.iloc[:44,].values).unsqueeze(0).to(torch.float32).to(device)\n\norigin_emb = F.normalize(best_model(origin_input),dim=1)\ntime()-start","metadata":{"execution":{"iopub.status.busy":"2024-10-29T07:40:14.416641Z","iopub.execute_input":"2024-10-29T07:40:14.417046Z","iopub.status.idle":"2024-10-29T07:40:14.468053Z","shell.execute_reply.started":"2024-10-29T07:40:14.416978Z","shell.execute_reply":"2024-10-29T07:40:14.466894Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.042151689529418945"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}